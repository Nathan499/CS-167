{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nathan499/CS-167/blob/main/Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project #2\n",
        "##Name:Nathan Larsen\n",
        "\n",
        "Proposed Points (out of 25): 25"
      ],
      "metadata": {
        "id": "rIepkBIuT_Pl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **I am going to create my own fish dataset through photos that I have and will import them on to my google drive.**\n",
        "\n",
        "https://www.kaggle.com/datasets/kapturovalexander/bitcoin-and-ethereum-prices-from-start-to-2023 \n",
        "\n",
        "https://www.kaggle.com/datasets/adilbhatti/bitcoin-and-fear-and-greed\n",
        "\n",
        "https://www.kaggle.com/datasets/kapturovalexander/bitcoin-and-other-14-most-significant-cryptos?select=2+Ethereum.csv\n",
        "\n",
        "https://www.kaggle.com/datasets/ryanholbrook/car-or-truck\n",
        "\n",
        "https://www.kaggle.com/datasets/mykhailokachan/overwatch-2-statistics"
      ],
      "metadata": {
        "id": "ZOoN19At-9hS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Problem\n",
        "State the problem you are trying to solve with this machine learning experiment. Include a description of the data, where you got the data, and what you're trying to predict.."
      ],
      "metadata": {
        "id": "HbwKLNhzP8YO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am going to use a convolutional neural network to analyze photos of different gemstones and see if it can correctly use softmax to correctly classify each gemstone. In this test I am going to perform different models with and and smaller kernels to see if this helps with accurcacy. I think that a model with padding and a smaller kernel will perform better. I got my data of the gemstones from Kaggle. Here is the link to the data sets:\n",
        "\n",
        "https://www.kaggle.com/datasets/lsind18/gemstones-images?resource=download\n",
        "\n"
      ],
      "metadata": {
        "id": "LwseoUsMmCz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Preparation\n",
        "Explain your data preparation. What did you have to do to get your data in shape for your experiments? Why are you certain that you data is clean and prepared for use in your algorithms?"
      ],
      "metadata": {
        "id": "qR_foVOeQVL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the data preparation the first thing that I had to do was download the images from kaggle and then make sure to extract the zip file to my drive."
      ],
      "metadata": {
        "id": "aMDJDnW_mOWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load and prepare your data here\n",
        "import keras\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import sys\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width = 200\n",
        "img_height = 200\n",
        "\n",
        "#the directories where our train and test data is\n",
        "train_data_dir = '/content/drive/MyDrive/CS 167/Gemstones/train'\n",
        "test_data_dir = '/content/drive/MyDrive/CS 167/Gemstones/test'\n",
        "\n",
        "#we will feed the training images to the neural network\n",
        "#in batches of 32 images at a time so we don't have \n",
        "#to load the entire data set into memory\n",
        "batch_size = 32\n",
        "\n",
        "# used to rescale the pixel values from [0, 255] to between 0 and 1\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "#These will look for our training and testing data\n",
        "#in their respective directory, and it will figure out\n",
        "#the class of each example based on the subfolder it is in\n",
        "train_data = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_data = datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n"
      ],
      "metadata": {
        "id": "9dUdBChRmKxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Research\n",
        "\n",
        "Put your code and your experiments here."
      ],
      "metadata": {
        "id": "Hc7HMmNPR10W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code goes here... don't forget to include graphs. Professor Urness loves graphs.\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "#setting up a sequential model with 3 convolutional layers, each with 32 feature maps\n",
        "#from regions that are 3x3 in the image\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape=(img_width, img_height, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "model.add(Flatten()) #flatten the convolutional layer so it can go into a fully-connected layer\n",
        "model.add(Dense(32)) #fully-connected layer\n",
        "model.add(Dense(1,activation='softmax'))\n",
        "\n",
        "# need to compile the model before you can use it\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "XfaACsEOR4U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Analysis\n",
        "\n",
        "What did you discover? What insights/recommendations do you have? What did you find that was interesting? Which model was your best model, which models didn't work well? Why do you think this is? In general, I want a discussion of your experiment, the results, and what they mean."
      ],
      "metadata": {
        "id": "2Qu9bYPLmiv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*your answer here*"
      ],
      "metadata": {
        "id": "k17sKBZUmqIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Bumps in the Road\n",
        "What challenges did you encounter? How did you overcome these challenges?"
      ],
      "metadata": {
        "id": "TemAuKxlm6dQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*your answer here*"
      ],
      "metadata": {
        "id": "zXEVEG9FnHgQ"
      }
    }
  ]
}